{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SQLContext, Row\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.format('com.databricks.spark.csv').\\\n",
    "options(header='true', inferschema='true').\\\n",
    "    load('file:///home/oxclo/datafiles/wind/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Station_ID='SF15', Station_Name='Warnerville Switchyard, Oakdale', Location_Label='Warnerville', Interval_Minutes=5, Interval_End_Time='2015-01-5? 00:05', Wind_Velocity_Mtr_Sec=1.628, Wind_Direction_Variance_Deg=8.1, Wind_Direction_Deg=148.5, Ambient_Temperature_Deg_C=0.92, Global_Horizontal_Irradiance=0.061)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertTime = lambda t: datetime.fromtimestamp(time.mktime(time.strptime(t, \"%Y-%m-%d? %H:%M\")))                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "toRow = lambda s: \\\n",
    "Row(stationid=s.Station_ID, \\\n",
    "time=convertTime(s.Interval_End_Time), \\\n",
    "direction=s.Wind_Direction_Deg, \\\n",
    "temp=s.Ambient_Temperature_Deg_C, \\\n",
    "velocity=s.Wind_Velocity_Mtr_Sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF = df.rdd.map(toRow).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF.write.format(\"org.apache.spark.sql.cassandra\").mode('append').options(table=\"winddate\", keyspace=\"wind\").save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
