{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-----+-----+\n",
      "|station|    datehour| wind| temp|\n",
      "+-------+------------+-----+-----+\n",
      "|   SF15|2014-01-04:0|0.671|3.466|\n",
      "|   SF15|2014-01-04:0|1.353|2.941|\n",
      "|   SF15|2014-01-04:0|0.907|2.606|\n",
      "|   SF15|2014-01-04:0|0.641|3.226|\n",
      "|   SF15|2014-01-04:0|  0.3|3.637|\n",
      "|   SF15|2014-01-04:0|0.193|3.383|\n",
      "|   SF15|2014-01-04:0|  0.0|2.998|\n",
      "|   SF15|2014-01-04:0|  0.0|2.765|\n",
      "|   SF15|2014-01-04:0|  0.0| 2.28|\n",
      "|   SF15|2014-01-04:0|  0.0|2.649|\n",
      "+-------+------------+-----+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-------+-------------+------------------+------------------+\n",
      "|station|     datehour|         avg(temp)|         avg(wind)|\n",
      "+-------+-------------+------------------+------------------+\n",
      "|   SF15| 2014-01-01:7| 4.964458333333332|0.8799791666666664|\n",
      "|   SF15|2014-05-03:15|27.309583333333336|2.4722083333333336|\n",
      "|   SF15| 2014-05-04:8|21.153750000000002|2.4801249999999997|\n",
      "|   SF15|2014-06-01:14| 33.20849999999999|2.1222833333333333|\n",
      "|   SF15|2014-09-05:10| 25.05479166666667|2.1636041666666666|\n",
      "|   SF15|2014-10-06:21|15.847166666666665|0.4448166666666665|\n",
      "|   SF37|2014-04-03:16|16.678499999999996|3.4063666666666665|\n",
      "|   SF37|2014-07-07:14| 17.74395833333333| 5.301333333333333|\n",
      "|   SF37| 2014-09-05:4|           16.0375|1.7272291666666668|\n",
      "|   SF37| 2014-09-06:8|          17.34625|1.8362708333333329|\n",
      "+-------+-------------+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-------+-------------+------------------+------------------+\n",
      "|station|     datehour|              temp|              wind|\n",
      "+-------+-------------+------------------+------------------+\n",
      "|   SF15| 2014-01-01:7| 4.964458333333332|0.8799791666666664|\n",
      "|   SF15|2014-05-03:15|27.309583333333336|2.4722083333333336|\n",
      "|   SF15| 2014-05-04:8|21.153750000000002|2.4801249999999997|\n",
      "|   SF15|2014-06-01:14| 33.20849999999999|2.1222833333333333|\n",
      "|   SF15|2014-09-05:10| 25.05479166666667|2.1636041666666666|\n",
      "|   SF15|2014-10-06:21|15.847166666666665|0.4448166666666665|\n",
      "|   SF37|2014-04-03:16|16.678499999999996|3.4063666666666665|\n",
      "|   SF37|2014-07-07:14| 17.74395833333333| 5.301333333333333|\n",
      "|   SF37| 2014-09-05:4|           16.0375|1.7272291666666668|\n",
      "|   SF37| 2014-09-06:8|          17.34625|1.8362708333333329|\n",
      "+-------+-------------+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from pyspark import SparkContext, SparkConf\n",
    "# from pyspark.sql import SQLContext, Row\n",
    "\n",
    "from dateutil.parser import parse\n",
    "from datetime import datetime\n",
    "\n",
    "# conf = SparkConf().setAppName(\"wind-sfpd\")\n",
    "# sc = SparkContext(conf=conf)\n",
    "sqlc = SQLContext(sc)\n",
    "\n",
    "# df = sqlc.read.format('com.databricks.spark.csv').\\\n",
    "# options(header='true', inferschema='true').\\\n",
    "# load('/home/oxclo/datafiles/wind2014/*.csv')\n",
    "\n",
    "df = spark.read.format('csv').options(header='true').load('/home/oxclo/datafiles/wind2014/*.csv')\n",
    "\n",
    "def date_and_hour(s):\n",
    "    dt = parse(s.replace('?',' '))\n",
    "    hour = dt.hour\n",
    "    return dt.strftime(\"%Y-%m-%d\")+\":\" +str(hour)\n",
    "\n",
    "tidied = df.rdd.map(lambda r: Row(station = r.Station_ID, datehour =date_and_hour(r.Interval_End_Time), \\\n",
    "temp=r.Ambient_Temperature_Deg_C, wind=r.Wind_Velocity_Mtr_Sec)).toDF()\n",
    "\n",
    "nonulls = tidied.filter(tidied.temp.isNotNull()).filter(tidied.wind.isNotNull())\n",
    "\n",
    "numbered = nonulls.rdd.map(lambda row: Row(station=row.station, datehour=row.datehour, wind=float(row.wind), temp=float(row.temp))).toDF()\n",
    "numbered.show(10)\n",
    "\n",
    "# tidied.registerTempTable(\"tempwind\")\n",
    "\n",
    "# averages = sqlc.sql(\"select station, datehour, avg(temp) as avgtemp, avg(wind) as avgwind from tempwind group by station, datehour\")\n",
    "\n",
    "averages = numbered.groupBy(['station','datehour']).agg({'temp':'avg', 'wind':'avg'})\n",
    "\n",
    "\n",
    "averages.show(10)\n",
    "\n",
    "cleanedaverages = averages.rdd.map(lambda row: Row(station=row.station, datehour=row.datehour, temp=row['avg(temp)'], wind=row['avg(wind)'])).toDF()\n",
    "cleanedaverages.show(10)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n",
      "|     datehour|                  yx|\n",
      "+-------------+--------------------+\n",
      "|2014-12-31:23|[37.7799444052046...|\n",
      "|2014-12-31:23|[37.7959918873778...|\n",
      "|2014-12-31:23|[37.7887772719153...|\n",
      "|2014-12-31:23|[37.7900712300699...|\n",
      "|2014-12-31:23|[37.8073339305952...|\n",
      "|2014-12-31:23|[37.7898859908661...|\n",
      "|2014-12-31:23|[37.7898859908661...|\n",
      "|2014-12-31:23|[37.7899968072158...|\n",
      "|2014-12-31:23|[37.7626702770872...|\n",
      "|2014-12-31:23|[37.7869408998805...|\n",
      "+-------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idf = spark.read.format('csv').options(header='true').load('/home/oxclo/datafiles/incidents/sfpd.csv')\n",
    "withyx2014 = idf.filter(idf.X.isNotNull()).filter(idf.Y.isNotNull()).filter(idf.Date.contains('2014'))\n",
    "tidy = withyx2014.rdd.map(lambda row: Row(datehour = date_and_hour(row.Date+\" \"+row.Time),yx=[float(row.Y),float(row.X)])).toDF()\n",
    "tidy.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n",
      "|station|     datehour|\n",
      "+-------+-------------+\n",
      "|   SF37|2014-12-31:23|\n",
      "|   SF37|2014-12-31:23|\n",
      "|   SF37|2014-12-31:23|\n",
      "|   SF18|2014-12-31:23|\n",
      "|   SF37|2014-12-31:23|\n",
      "|   SF37|2014-12-31:23|\n",
      "|   SF37|2014-12-31:23|\n",
      "|   SF37|2014-12-31:23|\n",
      "|   SF34|2014-12-31:23|\n",
      "|   SF37|2014-12-31:23|\n",
      "+-------+-------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-------+-------------+---------+\n",
      "|station|     datehour|incidents|\n",
      "+-------+-------------+---------+\n",
      "|   SF04|2014-12-31:18|        2|\n",
      "|   SF14| 2014-12-29:8|        1|\n",
      "|   SF19|2014-12-26:22|        4|\n",
      "|   SF34| 2014-12-25:0|        1|\n",
      "|   SF37| 2014-12-22:4|        1|\n",
      "|   SF37|2014-12-18:15|        8|\n",
      "|   SF36| 2014-12-18:5|        1|\n",
      "|   SF36|2014-12-16:21|        2|\n",
      "|   SF18|2014-12-16:20|        3|\n",
      "|   SF14| 2014-12-16:1|        2|\n",
      "|   SF04|2014-12-15:15|        3|\n",
      "|   SF37|2014-12-14:18|        8|\n",
      "|   SF34|2014-12-14:18|        2|\n",
      "|   SF19| 2014-12-14:1|        1|\n",
      "|   SF14|2014-12-12:12|        2|\n",
      "|   SF34| 2014-12-12:6|        1|\n",
      "|   SF04|2014-12-10:16|        1|\n",
      "|   SF07| 2014-12-09:2|        1|\n",
      "|   SF37| 2014-12-08:1|        5|\n",
      "|   SF37|2014-12-06:18|       14|\n",
      "|   SF37|2014-12-06:12|        5|\n",
      "|   SF37| 2014-12-06:0|        6|\n",
      "|   SF19|2014-12-03:12|        2|\n",
      "|   SF34|2014-12-02:15|        2|\n",
      "|   SF34|2014-11-29:18|        1|\n",
      "|   SF37|2014-11-28:16|       10|\n",
      "|   SF36|2014-11-26:13|        1|\n",
      "|   SF11|2014-11-21:13|        1|\n",
      "|   SF34|2014-11-21:12|        2|\n",
      "|   SF04|2014-11-20:16|        1|\n",
      "|   SF19|2014-11-20:15|        2|\n",
      "|   SF11| 2014-11-20:3|        1|\n",
      "|   SF37|2014-11-19:19|        8|\n",
      "|   SF18|2014-11-18:14|        3|\n",
      "|   SF34| 2014-11-17:2|        1|\n",
      "|   SF16|2014-11-16:10|        1|\n",
      "|   SF14|2014-11-12:22|        1|\n",
      "|   SF11| 2014-11-12:6|        1|\n",
      "|   SF11|2014-11-11:14|        2|\n",
      "|   SF04|2014-11-09:10|        2|\n",
      "|   SF11| 2014-11-09:5|        1|\n",
      "|   SF11|2014-11-08:22|        2|\n",
      "|   SF18|2014-11-08:16|        4|\n",
      "|   SF37| 2014-11-08:1|        7|\n",
      "|   SF18| 2014-11-07:6|        1|\n",
      "|   SF04|2014-11-06:15|        3|\n",
      "|   SF37|2014-11-04:21|        5|\n",
      "|   SF19|2014-11-03:19|        3|\n",
      "|   SF19|2014-11-01:19|        1|\n",
      "|   SF07|2014-11-01:17|        3|\n",
      "|   SF37|2014-10-28:20|        9|\n",
      "|   SF18| 2014-10-28:7|        2|\n",
      "|   SF19| 2014-10-26:3|        4|\n",
      "|   SF07|2014-10-22:21|        3|\n",
      "|   SF11| 2014-10-22:7|        2|\n",
      "|   SF04|2014-10-20:17|        7|\n",
      "|   SF07|2014-10-17:14|        3|\n",
      "|   SF34|2014-10-16:22|        2|\n",
      "|   SF18|2014-10-16:16|        4|\n",
      "|   SF36| 2014-10-16:6|        1|\n",
      "|   SF11| 2014-10-14:8|        3|\n",
      "|   SF37| 2014-10-13:2|        6|\n",
      "|   SF04|2014-10-12:15|        1|\n",
      "|   SF37| 2014-10-12:9|        5|\n",
      "|   SF16|2014-10-11:15|        1|\n",
      "|   SF11| 2014-10-10:6|        3|\n",
      "|   SF14|2014-10-09:19|        1|\n",
      "|   SF19| 2014-10-08:6|        4|\n",
      "|   SF37| 2014-10-06:7|        4|\n",
      "|   SF11| 2014-10-04:0|        6|\n",
      "|   SF37|2014-10-02:18|        9|\n",
      "|   SF18| 2014-09-27:7|        2|\n",
      "|   SF37| 2014-09-25:8|        5|\n",
      "|   SF34|2014-09-22:17|        6|\n",
      "|   SF18|2014-09-18:15|        2|\n",
      "|   SF11|2014-09-17:19|       10|\n",
      "|   SF07|2014-09-15:13|        1|\n",
      "|   SF07| 2014-09-15:1|        1|\n",
      "|   SF34| 2014-09-13:8|        2|\n",
      "|   SF16| 2014-09-11:9|        1|\n",
      "|   SF04| 2014-09-09:7|        1|\n",
      "|   SF34| 2014-09-09:4|        2|\n",
      "|   SF37| 2014-09-06:8|        1|\n",
      "|   SF37| 2014-09-05:4|        4|\n",
      "|   SF18|2014-09-03:18|        2|\n",
      "|   SF37| 2014-09-01:0|       12|\n",
      "|   SF04| 2014-08-30:6|        2|\n",
      "|   SF18| 2014-08-30:5|        2|\n",
      "|   SF18|2014-08-29:15|        7|\n",
      "|   SF34|2014-08-26:10|        1|\n",
      "|   SF14|2014-08-25:23|        3|\n",
      "|   SF11|2014-08-22:23|        2|\n",
      "|   SF04|2014-08-20:21|        1|\n",
      "|   SF07|2014-08-17:18|        1|\n",
      "|   SF37|2014-08-17:14|       14|\n",
      "|   SF19| 2014-08-09:8|        3|\n",
      "|   SF14| 2014-08-05:4|        1|\n",
      "|   SF19| 2014-08-04:9|        1|\n",
      "|   SF11| 2014-08-02:6|        1|\n",
      "|   SF11|2014-07-31:12|        3|\n",
      "+-------+-------------+---------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from scipy import spatial\n",
    "\n",
    "\n",
    "def locate(l,index,locations):\n",
    "    distance,i = index.query(l)\n",
    "    return locations[i]\n",
    "\n",
    "def map_yx_to_station(yx):\n",
    "    return locate(yx, \\\n",
    "        spatial.KDTree(array( \\\n",
    "        [[37.7816834,-122.3887657],\\\n",
    "        [37.7469112,-122.4821759],\\\n",
    "        [37.7411022,-120.804151],\\\n",
    "        [37.4834543,-122.3187302],\\\n",
    "        [37.7576436,-122.3916382],\\\n",
    "        [37.7970013,-122.4140409],\\\n",
    "        [37.748496,-122.4567461],\\\n",
    "        [37.7288155,-122.4210133],\\\n",
    "        [37.5839487,-121.9499339],\\\n",
    "        [37.7157156,-122.4145311],\\\n",
    "        [37.7329613,-122.5051491],\\\n",
    "        [37.7575891,-122.3923824],\\\n",
    "        [37.7521169,-122.4497687]])),\n",
    "        [\"SF18\", \"SF04\", \"SF15\", \"SF17\", \"SF36\", \"SF37\",\\\n",
    "        \"SF07\", \"SF11\", \"SF12\", \"SF14\", \"SF16\", \"SF19\", \"SF34\"] )\n",
    "\n",
    "# sqlc.udf.register('map_yx_to_station',map_yx_to_station)\n",
    "                  \n",
    "                  \n",
    "tidy.registerTempTable('incidents')\n",
    "\n",
    "# withstations = sqlc.sql(\"select map_yx_to_station(yx) as station, datehour from incidents\")\n",
    "withstations = tidy.rdd.map(lambda row: Row(station=map_yx_to_station(row.yx), datehour=row.datehour)).toDF()\n",
    "# print(map_yx_to_station([37.7816834,-122.3887657]))\n",
    "withstations.show(10)\n",
    "\n",
    "withstations.registerTempTable('stationincidents')\n",
    "\n",
    "incidentcount = sqlc.sql(\"select station, datehour, count(1) as incidents from stationincidents group by station, datehour\")\n",
    "incidentcount.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+------------------+------------------+---------+\n",
      "|station|     datehour|              temp|              wind|incidents|\n",
      "+-------+-------------+------------------+------------------+---------+\n",
      "|   SF04|2014-01-10:19|              null|              null|        1|\n",
      "|   SF04|2014-02-03:13|11.799791666666664|1.7297083333333336|        1|\n",
      "|   SF04|2014-02-06:16|13.486944444444447| 2.406222222222222|        1|\n",
      "|   SF04|2014-02-07:20|            8.4175|1.3776666666666666|        1|\n",
      "|   SF04|2014-02-09:23|              null|              null|        1|\n",
      "|   SF04| 2014-02-17:7|              null|              null|        1|\n",
      "|   SF04| 2014-02-21:3|              null|              null|        1|\n",
      "|   SF04|2014-03-23:19|              null|              null|        1|\n",
      "|   SF04|2014-04-07:10|12.728541666666667|2.6746041666666667|        1|\n",
      "|   SF04|2014-04-12:11|              null|              null|        2|\n",
      "+-------+-------------+------------------+------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined = cleanedaverages.join(incidentcount, ['station', 'datehour'], 'outer')\n",
    "joined.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroed = joined.rdd.map(lambda row: Row(station = row.station, datehour=row.datehour, temp = row.temp, wind = row.wind, incidents = row.incidents if row.incidents  else 0)).toDF()\n",
    "# zeroed.show(100)\n",
    "final = zeroed.filter(zeroed.temp.isNotNull()).filter(zeroed.wind.isNotNull()).filter(zeroed.temp!=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.24453833 0.06069799]\n",
      " [0.24453833 1.         0.24087844]\n",
      " [0.06069799 0.24087844 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.stat import Statistics\n",
    "\n",
    "vecs = final.rdd.map(lambda row: Vectors.dense([row.temp,row.wind,row.incidents]))\n",
    "\n",
    "print(Statistics.corr(vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
